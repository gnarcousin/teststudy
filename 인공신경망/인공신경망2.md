<h1>인공신경망</h1>

<h2> 20차시 - 자기 조직화 지도<h2>

<h2> 20-1. SOM (Self-Organazing-Map)</h2>

**자율신경망** = 자율적인 학습이 이루어지는 신경망

**SOM**
> 자율 신경망의 대표적인 모델
> **비지도 학습에 의한 클러스터링(군집화) 방법** 중 하나
> 고차원의 데이터들을 줄여서 가시화하는 방법
>> 3D, 4D >> 2D
> 1980년 튜브 코호넨에 의해서 고안됨 
>
> 입력층 / 출력층으로 구성된 **단층 신경망 구조**
> 출력층의 뉴런 = **2차원 배열**
>> 사각형 배열 / 육각형 배열 형태
 
![](../../1.png)

<h2> 20-2. 자기 조직화 지도의 학습 알고리즘</h2>

**SOM의 Winner 뉴런** = 입력 패턴과 가장 유사한 가중치를 갖는 출력층 뉴런  <br>

**SOM**의 학습 방법 = J(winner 뉴런)를 기준으로 반경 r을 설정해 **r 내의 뉴런들의 가중치**를 업데이트
<br><br>
<h2> 23차시 - 패턴의 유사도 </h2>

<h2> 23.1 경쟁식 신경망 </h2>

**경쟁식 신경망** = 패턴의 유사도 측정 도구 (해밍 거리 / 유클리드 거리)

> *Hamming Net / CP net으로 나뉨*  
> **패턴의 유사도** = 패턴들 사이의 일치하는 정도를 정량(수치)적으로 표현한 것  
>   
> 해밍 거리 = 비교된 패턴들의 사잇값이 다른 비트들의 갯수
>> 해밍 거리가 다를 수록 유사함  
>> 단순히 두 패턴의 비트를 비교하는 방식
<br><br>
<h2> 24차시 - Hamming Net </h2>

<h2> 24.1 Hamming Net </h2>

Hamming Net = 해밍 거리를 이용해 표본 패턴을 식별하는 신경망

> 입력 패턴이 n개의 픽셀이고 표본 패턴 수가 m개이면, **입 / 출력층은 각각 n / m개의 뉴런으로 구성**됨 
> ![](../../5.png)
> 표본 패턴의 개수가 1개인 경우 **가중치 W를 별도 학습하지 않고** 표본 패턴 s로부터 직접 값을 구할 수 있음

<h2> 24.2 Hamming Net의 표본 패턴 저장 </h2>

입력 패턴과 가장 유사한 표본 패턴을 찾는 법
> Hamming Net은 **경사 함수**를 사용함
> ![](../../21.png)
> 출력층 뉴런들 중 **출력값이 가장 큰 뉴런의 색인(index) J**를 찾음
>> 색인을 바탕으로 s(J)를 가장 유사한 표본 패턴으로 판단
<br><br>
<h2> 29차시 오류 역전파 알고리즘 </h2>

*BackPropagation (역전파) = error Backpropagation (오류 역전파)
= BP 알고리즘*    

**BP 알고리즘** = 다층 퍼셉트론의 학습 방법
> 효과적인 학습이 가능해 가장 널리 사용되는 방법임
> <br>
> 출력층의 오차 신호를 은닉층에 **역전파하여** 은닉층의 오차신호를 구함
>> 구한 은닉층의 **오차신호를 이용해** 입력층과 은닉층 사이의 가중치를 변경하는 방식
> ![](../../5-2.png)
<br><br>
<h2> 30차시 학습 인자 </h2>

<h2> 30.1 초기 가중치 </h2>

**BP 알고리즘의 문제점**
> 은닉층의 수가 많아지면 **학습이 매우 느려짐**
>> 경우에 따라 학습이 이루어지지 않을 수도 있음
> 오늘 날에는 다양한 방법으로 이를 해결해 심층 신경망을 널리 사용 가능

**학습 인자(매개 변수(Parameter) / 하이퍼 파라메터(Hyper Parameter))**

**매개 변수** = 학습에 의해 최적의 값이 결정되는 가중치와 바이어스(Bias)  

**하이퍼 파라메터(Hyperparameter)**
> 매개 변수 외의, 학습을 효과적으로 수행하기 위해 **설정해야하는 많은 요소들**
> **학습에 의해 찾을 수 없음** (인간이 수작업으로 찾아야 함)  
> 만들 수 있는 조합의 경우의 수가 매우 많아 최적의 파라미터를 찾기 어려움
>> 많은 경험과 시행 착오를 통해 얻은 **지식들을 바탕으로 값이 결정됨**
 
**초기 가중치**
> 신경망 학습에 있어서 **가중치의 초기화**는 매우 중요함
> 가중치의 초기화를 잘못하면 오차가 커질 수 있음
> Xavier 초기화나 He 초기화 방법을 주로 사용
 
<h2> 30.2 은닉층의 수</h2>
 
은닉층의 수는 사람이 결정하는 **하이퍼 파라메터**
> 학습 시간에 상당한 영향을 주기 때문에 하이퍼 파라메터 설정이 중요  
> 시행착오를 바탕으로 최적의 값 설정 필요
 
<h2> 30.3 비용 함수</h2>
 
*lost function = cost function = 비용 함수*
<br>
**손실을 최소화 하는 방향**(기울기가 감소)으로 학습(경사 하강법)이 진행됨

<h2> 30.4 Overfitting </h2>

신경망이 학습 데이터에 **과도화게 특화되어 학습**한 현상
> 학습에 사용된 데이터에 대해선 성능이 좋지만 **새로운 데이터에 대해서는 오히려 성능이 떨어짐**
  
**언더피팅** = 학습이 너무 미진한 상황 - 데이터를 잘 구분하기 힘듬  
**적절한 학습** = 오류는 발생할 수 있으나 적절한 상황  
**오버피팅** = 과도한 학습이 이루어짐 - 데이터를 엄격하게 구분함
  
> 일반적으로 **학습 데이터가 너무 적거나 심층 신경망 속 은닉층의 수가 너무 많아** 발생  
> 해결을 위해 **정규화 / 드롭 아웃** 등의 기법 개발
 
**정규화**
> L1 / L2 정규화로 구분됨  
> 페널티라는 항목을 비용 함수에 추가, 특정 가중치가 지나치게 커지는 것을 억제하여 오버피팅 방지

**드롭 아웃**
> 입력층과 은닉층의 **일부 뉴런들과 해당 뉴런들에 연결된 가중치들을 학습에서 제외**시킴
>> 제외되는 뉴런들은 **랜덤**하게 결정
> 학습 단계에서 적용된 뉴런들은 실제 응용 단계에서 다시 포함시켜 사용
<br><br>
<h2> 31차시 컨볼루션 신경망 </h2>

 <h2> 31.1 특징 </h2>

**인공신경망(Artificial Neural Network, ANN)**
<br>
**심층 신경망(Deep Neural Network, DNN)**
> 은닉층이 2개 이상인 다층 신경망
<br>
**컨볼루션 신경망(Convolution Neural Network, CNN)**
> 인간 뇌의 시각피질에서 **영상을 처리**하는 것과 유사한 기능을 하는 신경망
> **영상 인식 분야**에 매우 유용하게 사용됨
> 기존 신경망과 다르게 **특징 추출과 분류기 모두 신경망을 사용**함
 
![6](https://user-images.githubusercontent.com/107753319/206846139-65495ead-215b-4e74-a80a-a3a592bd58d7.png)

<h2> 31.2 CNN 구조 </h2>
 
> **특칭 추출 신경망**과 **분류 신경망**으로 구현되어 있음
>> 분류 신경망 부분은 일반적인 ANN과 DNN과 동일
![7](https://user-images.githubusercontent.com/107753319/206846594-119abf7e-d0a6-4331-9601-dae5c616871f.png)

> **컨볼루션 계층** = 필터를 통해 입력 영상의 지역적인 **특징 추출**  
> **풀링 계층** = 추출된 특징들 중 **대표값을 뽑아 평균값**을 만들어냄  
> **분류 신경망** = 모든 뉴런들이 연결되어 있어 **완전 연결 계층(Fully Connected, FC계층)**이라고도 부름  

**특징 추출 신경망** 
> 평균 풀링 (평균값으로 대표값을 뽑아냄) | 최대 풀링(최댓값으로 대표값을 뽑아냄) 방식 존재
> 일반적인 컨볼루션 계층의 활성화 함수는 ReLU 함수임

**분류 신경망**
> 특징 추출 신경망의 **후단에 위치**함
> 기존에 사용된 **신경망 분류기와 동일한 구조임**
>
> 최근 분류신경망의 활성화 함수는 **소프트맥스 함수**를 사용함
>> 일반적으로는 시그모이드 함수 사용

 **심층 컨볼루션 신경망**
 > 컨볼루션 계층과 풀링 계층을 **반복적으로 여러 개 배치**하는 형태
